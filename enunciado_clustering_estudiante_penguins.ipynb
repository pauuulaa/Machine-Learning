{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f3e8f3c",
      "metadata": {},
      "source": [
        "# Comparativa de Clustering: K-Means, DBSCAN y Jerárquico\n",
        "\n",
        "**Objetivo:** comparar tres métodos de clustering en un dataset real y elegir **el mejor** según el **coeficiente de silueta** (y **Elbow** solo para K-Means).\n",
        "\n",
        "**Dataset elegido:** **Palmer Penguins** (medidas de pingüinos) — datos libres y fáciles de obtener.\n",
        "\n",
        "- Página del proyecto: <https://allisonhorst.github.io/palmerpenguins/>\n",
        "- CSV directo (penguins_clean): <https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins_clean.csv>\n",
        "\n",
        "> Nota: **NO uses la columna de especie** (`species`) para entrenar (clustering es no supervisado). Se puede usr más tarde sólo para **interpretación** si lo deseas, pero **nunca** para ajustar los modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a520759d",
      "metadata": {},
      "source": [
        "## Requisitos\n",
        "- Trabajar siempre con **variables numéricas** y **datos escalados**.\n",
        "- Evaluación:\n",
        "  - **K-Means:** curva **Elbow** (inercia) para k=2..10 + **Silhouette** para k=2..10.\n",
        "  - **DBSCAN:** probar varias combinaciones de `eps` y `min_samples`; reportar **Silhouette**, nº de clústeres (excl. ruido) y % ruido.\n",
        "  - **Jerárquico:** probar `linkage` en {`ward`, `complete`, `average`} y k=2..10; reportar **Silhouette**.\n",
        "- Conclusión final: elige método y configuración (parámetros) y justifica **en 8–12 líneas**.\n",
        "\n",
        "**Importante (API de scikit-learn):**\n",
        "- `KMeans` **sí** tiene `.predict(X)` para etiquetar nuevos puntos.\n",
        "- `DBSCAN` y `AgglomerativeClustering` **no** tienen `.predict`. Usa `fit_predict(X)` y el atributo `.labels_` tras el ajuste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b4c92e",
      "metadata": {},
      "source": [
        "## 0) Preparación del entorno\n",
        "- Necesitas tener instalado `pandas`, `numpy`, `scikit-learn`, `matplotlib`.\n",
        "- Fija `random_state=42` (u otro) cuando aplique para reproducibilidad.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7aae59",
      "metadata": {},
      "source": [
        "## 1) Descarga y carga de datos\n",
        "1. Descarga el CSV desde la URL indicada.\n",
        "2. Cárgalo en un `DataFrame`.\n",
        "3. Inspecciona forma, nombres de columnas y tipos.\n",
        "4. Identifica columnas **numéricas** que usarás como `X` (excluye `species` y otras no numéricas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8824409",
      "metadata": {
        "tags": [
          "student-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# TODO: Cargar dataset Palmer Penguins en un DataFrame df\n",
        "# TODO: Mostrar df.head(), df.info(), df.describe()\n",
        "# TODO: Seleccionar X solo con columnas numéricas (excluyendo target/contexto) IMPORTANTE, LA X INCLUIRA SOLO LAS VARIABLES NUMÉRICAS!!!\n",
        "# df = ...\n",
        "# X = ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3762b8c",
      "metadata": {},
      "source": [
        "## 2) Limpieza mínima y normalización\n",
        "1. Elimina duplicados y filas con nulos en las columnas numéricas escogidas.\n",
        "2. **Estandariza** (`StandardScaler`) para tener media 0 y varianza 1.\n",
        "3. Guarda el array escalado como `X_scaled` (será tu base para todos los modelos).\n",
        "\n",
        "> **Por qué escalamos:** Todas las distancias (Euclídeas) y medidas de densidad de los modelos dependen de la escala; mezclar variables en escalas distintas sesga los resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e53543",
      "metadata": {
        "tags": [
          "student-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# TODO: Limpieza básica (drop_duplicates / dropna) y escalado con StandardScaler\n",
        "# \n",
        "# scaler = ...\n",
        "# X_scaled = ...\n",
        "# print(X.shape, '->', X_scaled.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31447b83",
      "metadata": {},
      "source": [
        "## 3) K-Means\n",
        "**Objetivo:**\n",
        "- Bucle `k` en 2..10.\n",
        "- Guardar por cada `k`: **inercia** (suma de distancias al centroide) y **Silhouette**.\n",
        "- Seleccionar `k` final apoyándote en **Elbow** + **Silhouette**.\n",
        "\n",
        "**Indicaciones específicas:**\n",
        "- Usa `KMeans(n_clusters=k, random_state=42)`.\n",
        "- Tras ajustar, obtén etiquetas con `.labels_` o usando `.predict(X_scaled)`.\n",
        "- Para Silhouette: `sklearn.metrics.silhouette_score(X_scaled, labels)`.\n",
        "- Traza **Inercia vs k** y **Silhouette vs k** (dos gráficos separados). Explica en 2-3 líneas tu elección de `k`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1943b918",
      "metadata": {
        "tags": [
          "student-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# TODO: Bucle K-Means para k=2..10, guardar inercia y silhouette\n",
        "# TODO: Graficar Elbow (inercia vs k) y Silhouette vs k\n",
        "# TODO: Elegir k_final y ajustar modelo final; obtener labels_kmeans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "defe60e4",
      "metadata": {},
      "source": [
        "## 4) DBSCAN\n",
        "**Objetivo:** explorar `eps` y `min_samples` en una rejilla pequeña y comparar resultados.\n",
        "\n",
        "**Indicaciones específicas:**\n",
        "- Probar `eps` en valores razonables (por ejemplo: 0.3, 0.5, 0.7, 0.9) y `min_samples` en {3, 5, 7}.\n",
        "- Para cada combinación: ajusta con `DBSCAN(eps=?, min_samples=?)` sobre `X_scaled`.\n",
        "- Extrae etiquetas con `.labels_`.\n",
        "- Calcula **nº de clústeres** (excluyendo `-1`) y **% de ruido** (`label == -1`).\n",
        "- Calcula **Silhouette** **solo si** hay al menos **2** clústeres válidos (sin contar ruido). Si no, anota \"no aplicable\".\n",
        "- Elige una combinación final y justifica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26270368",
      "metadata": {
        "tags": [
          "student-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# TODO: Grid pequeño de DBSCAN: probar eps y min_samples\n",
        "# TODO: Para cada combinación, registrar #clusters válidos, %ruido y silhouette (si aplica)\n",
        "# TODO: Elegir configuración final; obtener labels_dbscan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491c60f4",
      "metadata": {},
      "source": [
        "## 5) Aglomerativo Jerárquico\n",
        "**Objetivo:** probar distintas reglas de enlace y diferentes `k`.\n",
        "\n",
        "**Indicaciones específicas:**\n",
        "- Probar `linkage` en {`ward`, `complete`, `average`}.\n",
        "- Para cada `linkage`, probar `n_clusters` en 2..10.\n",
        "- Ajustar con `AgglomerativeClustering(n_clusters=k, linkage=..., metric='euclidean')`.\n",
        "- Obtener etiquetas con `.fit_predict(X_scaled)` o del atributo `.labels_`.\n",
        "- Calcular **Silhouette** y registrar los resultados en una tabla.\n",
        "- Elegir la pareja (linkage, k) final y justificar.\n",
        "\n",
        "> Recordatorio: `ward` requiere métrica euclídea (en scikit-learn es implícita). No hay `.predict()` para nuevos datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3cd2ab",
      "metadata": {
        "tags": [
          "student-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# TODO: Bucle Agglomerative: linkage en {'ward','complete','average'} y k=2..10\n",
        "# TODO: Calcular silhouette para cada combinación y elegir la mejor; obtener labels_agglom\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "572566be",
      "metadata": {},
      "source": [
        "## 6) Comparativa y Conclusión\n",
        "1. Resume en una **tabla** el **mejor** resultado de cada método (método, parámetros, silhouette, nº de clústeres y notas relevantes como % ruido en DBSCAN).\n",
        "2. Escribe una **conclusión de 8–12 líneas** justificando el **método ganador** para estos datos y por qué descartas las alternativas (forma de clústeres, sensibilidad a parámetros, presencia de ruido/outliers, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56be6e0d",
      "metadata": {
        "tags": [
          "student-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# TODO: Construir la tabla comparativa final y redactar la conclusión (puedes imprimir un markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a9f54db",
      "metadata": {},
      "source": [
        "---\n",
        "## Tips rápidos\n",
        "- **Escala siempre** antes de ajustar los modelos.\n",
        "- Si la Silhouette es negativa o muy baja, revisa parámetros.\n",
        "- En DBSCAN, `eps` muy pequeño -> muchos ruidos; `eps` muy grande -> pocos clústeres (puede mezclarlo todo).\n",
        "- K-Means es sensible a outliers; DBSCAN puede marcarlos como ruido; el jerárquico con `complete` favorece clústeres compactos.\n",
        "- Documenta tus decisiones (por qué ese `k`, ese `eps`, ese `linkage`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40cb40bf",
      "metadata": {},
      "source": [
        "# BONUS EXTRA\n",
        "\n",
        "### Validación tramposa\n",
        "\n",
        "Usa la columna species para evaluar qué tan “puras” son las asignaciones del mejor modelo de cada método.\n",
        "\n",
        "Creando una matriz de confusión entre clúster y especie y sacando accuracy.\n",
        "\n",
        "Comenta usando distintos valores de eps y min_samples en DBSCAN.\n",
        "\n",
        "### Detección de anomalías con DBSCAN\n",
        "\n",
        "Con tu configuración de DBSCAN, analiza los puntos con label = -1 (ruido): ¿qué tienen en común (rangos extremos de masa, culmen, etc.)?\n",
        "\n",
        "Genera una tabla o un par de graficas (histogramas comparativos, por ejemplo) para ilustrar las diferencias entre los puntos de ruido y los puntos asignados a clústeres.\n"
      ]
    }
  ],
  "metadata": {
    "created": "2025-10-17T10:56:23.151465Z",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
