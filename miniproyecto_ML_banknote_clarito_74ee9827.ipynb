{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Mini‑proyecto ML (Clasificación) — Banknote Authentication (UCI) — **Versión sencilla y muy clara**\n\n**Objetivo:** construir un *pipeline* de clasificación **tradicional** y **didáctico** con 4 modelos:\n**KNN, SVM, Árbol de Decisión y Random Forest**.  \nPriorizamos **claridad de código** frente a evitar repeticiones.\n\n**Dataset:** UCI Banknote Authentication — estadísticas (wavelet) de imágenes de billetes.  \n**Target:** `class` (0 = auténtico, 1 = falso).\n\n---\n\n## Guía de la libreta\n1. Instalación opcional de dependencias.  \n2. Carga de datos desde **una** URL y EDA mínima.  \n3. División *train/test* (sin estratificar, por simplicidad).  \n4. Experimentos **por separado** para cada modelo (sin bucles ni *helpers*):  \n   - Preparación (escalado solo donde conviene)  \n   - Definición del modelo  \n   - Búsqueda de hiperparámetros con `GridSearchCV` (rejillas pequeñas)  \n   - Entrenamiento y **reporte de métricas** (accuracy, precision, recall, F1, ROC‑AUC, PR‑AUC), matriz de confusión, curvas ROC y PR.  \n5. Discusión detallada de **hiperparámetros** y **rangos típicos**.\n\n> Nota: el código es **intencionadamente repetitivo** para que cada bloque sea legible de forma aislada.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Instalación opcional de dependencias"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# !pip -q install numpy pandas scikit-learn matplotlib"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Imports y configuración"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n                             roc_auc_score, average_precision_score, roc_curve,\n                             precision_recall_curve, ConfusionMatrixDisplay, classification_report)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Carga del dataset (UNA URL) y EDA mínima\nUsamos la URL original de UCI (CSV sin cabecera). Si alguna vez no funcionase, **cambia tú la URL** aquí.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\ncols = ['variance', 'skewness', 'curtosis', 'entropy', 'class']\ndf = pd.read_csv(url, header=None, names=cols)\n\nprint('Dimensiones:', df.shape)\ndisplay(df.head())\nprint('\\nTipos:')\nprint(df.dtypes)\nprint('\\nNulos por columna:')\nprint(df.isna().sum())\n\nprint('\\nDistribución de la clase (0=auténtico, 1=falso):')\nprint(df['class'].value_counts(normalize=True).rename('ratio'))\n\ndisplay(df.describe().T)\n\ndf.drop(columns=['class']).hist(bins=30, figsize=(10,6))\nplt.suptitle('Distribución de variables (features)', y=1.02)\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Train/Test split (sin estratificar, por simplicidad)\n> Nota: en casos reales, con clases desbalanceadas, **sí** conviene estratificar.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "X = df.drop(columns=['class'])\ny = df['class']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=RANDOM_STATE\n)\n\nprint('Train shape:', X_train.shape, ' Test shape:', X_test.shape)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 5) Modelo 1 — KNN (k-Nearest Neighbors)\n\n### ¿Cuándo usar escalado?\nKNN usa distancias, así que **escalamos** las *features* para que todas estén en la misma magnitud.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, roc_curve, precision_recall_curve\n\nscaler_knn = StandardScaler()\nX_train_knn = scaler_knn.fit_transform(X_train)\nX_test_knn = scaler_knn.transform(X_test)\n\nknn = KNeighborsClassifier()\n\nparam_grid_knn = {\n    'n_neighbors': [3, 5, 7, 11],\n    'weights': ['uniform', 'distance'],\n    'p': [1, 2]\n}\n\ngs_knn = GridSearchCV(knn, param_grid_knn, scoring='f1', cv=5, n_jobs=-1, refit=True)\ngs_knn.fit(X_train_knn, y_train)\n\nprint('Mejor F1 (cv):', round(gs_knn.best_score_, 3))\nprint('Mejores params:', gs_knn.best_params_)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "best_knn = gs_knn.best_estimator_\ny_pred_knn = best_knn.predict(X_test_knn)\ny_score_knn = best_knn.predict_proba(X_test_knn)[:, 1]\n\nacc = accuracy_score(y_test, y_pred_knn)\nprec = precision_score(y_test, y_pred_knn, zero_division=0)\nrec = recall_score(y_test, y_pred_knn, zero_division=0)\nf1 = f1_score(y_test, y_pred_knn, zero_division=0)\nrocauc = roc_auc_score(y_test, y_score_knn)\nprauc = average_precision_score(y_test, y_score_knn)\n\nprint('KNN — Métricas test')\nprint(f'Accuracy: {acc:.3f}  Precision: {prec:.3f}  Recall: {rec:.3f}  F1: {f1:.3f}')\nprint(f'ROC-AUC: {rocauc:.3f}  PR-AUC: {prauc:.3f}\\n')\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn, display_labels=['Auténtico (0)','Falso (1)'])\nplt.title('KNN — Matriz de confusión'); plt.grid(False); plt.show()\n\nfpr, tpr, _ = roc_curve(y_test, y_score_knn)\nplt.figure(figsize=(6,5)); plt.plot(fpr, tpr, label='KNN')\nplt.plot([0,1],[0,1],'--', linewidth=1); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('KNN — ROC'); plt.legend(); plt.grid(True); plt.show()\n\nprecision, recall, _ = precision_recall_curve(y_test, y_score_knn)\nplt.figure(figsize=(6,5)); plt.plot(recall, precision, label='KNN')\nbaseline = (y_test==1).mean()\nplt.hlines(baseline, 0, 1, linestyles='--')\nplt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('KNN — Precision-Recall'); plt.legend(); plt.grid(True); plt.show()\n\nprint(classification_report(y_test, y_pred_knn, digits=3))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 6) Modelo 2 — SVM (SVC con kernel RBF)\n\n### Escalado\nSVM también se beneficia del **escalado** de *features*.\n\n> Nota: activamos `probability=True` para obtener probabilidades (necesario para ROC/PR)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "scaler_svm = StandardScaler()\nX_train_svm = scaler_svm.fit_transform(X_train)\nX_test_svm = scaler_svm.transform(X_test)\n\nsvm = SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE)\n\nparam_grid_svm = {\n    'C': [0.1, 1, 10],\n    'gamma': ['scale', 'auto']\n}\n\ngs_svm = GridSearchCV(svm, param_grid_svm, scoring='f1', cv=5, n_jobs=-1, refit=True)\ngs_svm.fit(X_train_svm, y_train)\n\nprint('Mejor F1 (cv):', round(gs_svm.best_score_, 3))\nprint('Mejores params:', gs_svm.best_params_)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "best_svm = gs_svm.best_estimator_\ny_pred_svm = best_svm.predict(X_test_svm)\ny_score_svm = best_svm.predict_proba(X_test_svm)[:, 1]\n\nacc = accuracy_score(y_test, y_pred_svm)\nprec = precision_score(y_test, y_pred_svm, zero_division=0)\nrec = recall_score(y_test, y_pred_svm, zero_division=0)\nf1 = f1_score(y_test, y_pred_svm, zero_division=0)\nrocauc = roc_auc_score(y_test, y_score_svm)\nprauc = average_precision_score(y_test, y_score_svm)\n\nprint('SVM — Métricas test')\nprint(f'Accuracy: {acc:.3f}  Precision: {prec:.3f}  Recall: {rec:.3f}  F1: {f1:.3f}')\nprint(f'ROC-AUC: {rocauc:.3f}  PR-AUC: {prauc:.3f}\\n')\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_svm, display_labels=['Auténtico (0)','Falso (1)'])\nplt.title('SVM — Matriz de confusión'); plt.grid(False); plt.show()\n\nfpr, tpr, _ = roc_curve(y_test, y_score_svm)\nplt.figure(figsize=(6,5)); plt.plot(fpr, tpr, label='SVM')\nplt.plot([0,1],[0,1],'--', linewidth=1); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('SVM — ROC'); plt.legend(); plt.grid(True); plt.show()\n\nprecision, recall, _ = precision_recall_curve(y_test, y_score_svm)\nplt.figure(figsize=(6,5)); plt.plot(recall, precision, label='SVM')\nbaseline = (y_test==1).mean()\nplt.hlines(baseline, 0, 1, linestyles='--')\nplt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('SVM — Precision-Recall'); plt.legend(); plt.grid(True); plt.show()\n\nprint(classification_report(y_test, y_pred_svm, digits=3))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 7) Modelo 3 — Árbol de Decisión\n\n### Escalado\nLos árboles **no necesitan** escalado (se basan en umbrales por variable)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n\nparam_grid_dt = {\n    'max_depth': [None, 3, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'min_samples_split': [2, 5, 10],\n    'criterion': ['gini', 'entropy']\n}\n\ngs_dt = GridSearchCV(dt, param_grid_dt, scoring='f1', cv=5, n_jobs=-1, refit=True)\ngs_dt.fit(X_train, y_train)\n\nprint('Mejor F1 (cv):', round(gs_dt.best_score_, 3))\nprint('Mejores params:', gs_dt.best_params_)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "best_dt = gs_dt.best_estimator_\ny_pred_dt = best_dt.predict(X_test)\ny_score_dt = best_dt.predict_proba(X_test)[:, 1]\n\nacc = accuracy_score(y_test, y_pred_dt)\nprec = precision_score(y_test, y_pred_dt, zero_division=0)\nrec = recall_score(y_test, y_pred_dt, zero_division=0)\nf1 = f1_score(y_test, y_pred_dt, zero_division=0)\nrocauc = roc_auc_score(y_test, y_score_dt)\nprauc = average_precision_score(y_test, y_score_dt)\n\nprint('Decision Tree — Métricas test')\nprint(f'Accuracy: {acc:.3f}  Precision: {prec:.3f}  Recall: {rec:.3f}  F1: {f1:.3f}')\nprint(f'ROC-AUC: {rocauc:.3f}  PR-AUC: {prauc:.3f}\\n')\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_dt, display_labels=['Auténtico (0)','Falso (1)'])\nplt.title('Decision Tree — Matriz de confusión'); plt.grid(False); plt.show()\n\nfpr, tpr, _ = roc_curve(y_test, y_score_dt)\nplt.figure(figsize=(6,5)); plt.plot(fpr, tpr, label='Decision Tree')\nplt.plot([0,1],[0,1],'--', linewidth=1); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('Decision Tree — ROC'); plt.legend(); plt.grid(True); plt.show()\n\nprecision, recall, _ = precision_recall_curve(y_test, y_score_dt)\nplt.figure(figsize=(6,5)); plt.plot(recall, precision, label='Decision Tree')\nbaseline = (y_test==1).mean()\nplt.hlines(baseline, 0, 1, linestyles='--')\nplt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Decision Tree — Precision-Recall'); plt.legend(); plt.grid(True); plt.show()\n\nprint(classification_report(y_test, y_pred_dt, digits=3))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 8) Modelo 4 — Random Forest\n\n### Escalado\nTampoco necesita escalado.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n\nparam_grid_rf = {\n    'n_estimators': [100, 200],\n    'max_depth': [None, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2', None]\n}\n\ngs_rf = GridSearchCV(rf, param_grid_rf, scoring='f1', cv=5, n_jobs=-1, refit=True)\ngs_rf.fit(X_train, y_train)\n\nprint('Mejor F1 (cv):', round(gs_rf.best_score_, 3))\nprint('Mejores params:', gs_rf.best_params_)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "best_rf = gs_rf.best_estimator_\ny_pred_rf = best_rf.predict(X_test)\ny_score_rf = best_rf.predict_proba(X_test)[:, 1]\n\nacc = accuracy_score(y_test, y_pred_rf)\nprec = precision_score(y_test, y_pred_rf, zero_division=0)\nrec = recall_score(y_test, y_pred_rf, zero_division=0)\nf1 = f1_score(y_test, y_pred_rf, zero_division=0)\nrocauc = roc_auc_score(y_test, y_score_rf)\nprauc = average_precision_score(y_test, y_score_rf)\n\nprint('Random Forest — Métricas test')\nprint(f'Accuracy: {acc:.3f}  Precision: {prec:.3f}  Recall: {rec:.3f}  F1: {f1:.3f}')\nprint(f'ROC-AUC: {rocauc:.3f}  PR-AUC: {prauc:.3f}\\n')\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf, display_labels=['Auténtico (0)','Falso (1)'])\nplt.title('Random Forest — Matriz de confusión'); plt.grid(False); plt.show()\n\nfpr, tpr, _ = roc_curve(y_test, y_score_rf)\nplt.figure(figsize=(6,5)); plt.plot(fpr, tpr, label='Random Forest')\nplt.plot([0,1],[0,1],'--', linewidth=1); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('Random Forest — ROC'); plt.legend(); plt.grid(True); plt.show()\n\nprecision, recall, _ = precision_recall_curve(y_test, y_score_rf)\nplt.figure(figsize=(6,5)); plt.plot(recall, precision, label='Random Forest')\nbaseline = (y_test==1).mean()\nplt.hlines(baseline, 0, 1, linestyles='--')\nplt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Random Forest — Precision-Recall'); plt.legend(); plt.grid(True); plt.show()\n\nprint(classification_report(y_test, y_pred_rf, digits=3))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9) Hiperparámetros — ¿Qué hacen y qué rangos tienen sentido?\n\n### KNN\n- **`n_neighbors (k)`**: nº de vecinos a considerar.  \n  - Pequeño (3–5): fronteras muy detalladas, **menos bias** y **más varianza** (sensible a ruido).  \n  - Grande (7–25): fronteras suaves, **más bias** y **menos varianza**.  \n  - Regla práctica: probar varios impares para evitar empates.\n- **`weights`**: `'uniform'` (todos igual) vs `'distance'` (cercanos pesan más).  \n  - `'distance'` suele mejorar cuando hay densidades desiguales o outliers.\n- **`p`** (Minkowski): `p=2` (Euclídea) es estándar; `p=1` (Manhattan) puede ser más robusta a outliers.\n- **Consejo**: siempre **escalar** antes de KNN.\n\n---\n\n### SVM (SVC con kernel RBF)\n- **`C`** (penalización): controla cuánto penalizamos errores en entrenamiento.  \n  - **Grande** (10, 100): margen estrecho, bajo bias, riesgo de **overfit**.  \n  - **Pequeño** (0.1, 0.01): margen amplio, más bias, más **regularización**.\n- **`gamma`**: alcance de la influencia de cada punto.  \n  - **Alto**: regiones muy locales (sobreajuste).  \n  - **Bajo**: regiones suaves (infra‑ajuste).  \n  - `'scale'` suele ser una buena base.\n- **Consejo**: **escalar** siempre.\n\n---\n\n### Decision Tree\n- **`max_depth`**: límite de profundidad.   \n  - `None` (sin límite) → riesgo de overfit; 3–20 típicos según datos.\n- **`min_samples_leaf`**: ejemplos mínimos por hoja; subirlo suaviza y reduce varianza (2–10 razonable).\n- **`min_samples_split`**: mínimo para dividir un nodo; subirlo evita splits con muy pocos datos.\n- **`criterion`**: `'gini'` o `'entropy'` (rendimientos similares).\n\n---\n\n### Random Forest\n- **`n_estimators`**: nº de árboles; 100–300 suele bastar (más = menos varianza y más coste).  \n- **`max_depth`/`min_samples_leaf`**: controlan complejidad por árbol (evitan overfit).  \n- **`max_features`**: nº de *features* consideradas por split; `'sqrt'` es muy común en clasificación.\n- **Importancias**: permiten ver qué variables aportan más (no es causalidad).\n\n---\n\n### Métricas — recordatorio rápido\n- **Accuracy** (acierto global) — bien con clases balanceadas.  \n- **Precision** (evitar FP), **Recall** (evitar FN), **F1** (equilibrio).  \n- **ROC‑AUC** (ranking global de puntuaciones) y **PR‑AUC** (mejor con clases raras).\n\n> En casos reales: ajustar **umbral**, calibrar probabilidades y analizar errores por tipo.\n"
    }
  ]
}